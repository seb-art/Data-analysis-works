{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaO9tN3qZeNQ"
   },
   "source": [
    "# Deep Learning: Assignment 1. Cat, Dog, Car or Bike?\n",
    "\n",
    "**Dataset:** You are provided with a dataset which contains more than 3000 pictures with either a cat, a dog, a motorbike or a car. The dataset has already been split in training, test and validation sets. Your task is to build and train a CNN which is able to recognize which object is depicted in the picture. To this end, you must use and change the code we presented during our tutorial. You should copy and unzip the dataset in your local directory (do not change the name of the directory), namely the same directory where this jupyter notebook is going to be stored. \n",
    "\n",
    "**Python and Keras version.** We recommend you to use Python 3.6 (there might be some incompatibility issues between keras and the most recent versions of Python). We also recommend to use TensorFlow 2.1.0 and Keras 2.3.1, which are the settings we used to test everything. You can find the documentation for keras at the following address https://keras.io/layers/convolutional/.\n",
    "\n",
    "**What to submit:** You should post on moodle this jupyter notebook filled will all the answers to the questions, the Python code and the plots. Do not change any part of the code that is provided to you, unless explicitly asked. The answers to the questions should be provided below at the end of the notebook. You should also post on moodle the model for question 5 (name of the model \"modelQ5.h1\"). In case your model has size larger than 100MB please provide a link to Google Drive or other storage services. **Important**: For each question you will get 0 points if the code or any of the plots are missing or the code is not correct.\n",
    "\n",
    "**Image Size** You should use image size **32x32** for the first three questions. You can use higher resolutions for questions 4 and 5. We kindly ask you to use your machine whenever possible, in order to avoid the GPU farm to be overwhelmed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJIlGGKsZeNW"
   },
   "source": [
    "## Install.md\n",
    "Build the enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104215,
     "status": "ok",
     "timestamp": 1681117264457,
     "user": {
      "displayName": "Pegasus Lee",
      "userId": "06519879725136127673"
     },
     "user_tz": -480
    },
    "id": "GeAQmzC-ZeNW",
    "outputId": "fc754569-024a-473a-818a-85ea5b42404c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kiman\\anaconda3\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kiman\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\kiman\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kiman\\anaconda3\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kiman\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kiman\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kiman\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\kiman\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kiman\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kiman\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.6.0\n",
    "!pip install keras==2.3.1\n",
    "!pip install matplotlib\n",
    "# You can ignore the warnings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjPqloIvZeNY"
   },
   "source": [
    "## Prepare the dataset\n",
    "We have prepared the dataset for you. You should download it in:\n",
    "https://drive.google.com/file/d/1wTuQyTtHCQq-xawNkIUEWT-ga1FrVOrj/view?usp=sharing\n",
    "\n",
    "Unzip the file and the folder structure is shown as:\n",
    "```\n",
    "Assign1\n",
    "├── Skeleton_Assignment1.ipynb\n",
    "├── cat_dog_car_bike\n",
    "│   ├── train\n",
    "│   ├── val\n",
    "│   ├── test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gb9sN54UZeNY"
   },
   "source": [
    "##### Question 1 (CNN Architecture) \n",
    "\n",
    "Define a CNN architecture with the following layers stacked on top of each other in the following order:\n",
    "1. A convolutional layer with 32 5 × 5 filters. \n",
    "2. A max Pooling Layer with size 2 × 2.\n",
    "3. A convolutional layer with 64 5 × 5 filters. \n",
    "4. A max Pooling Layer with size 2 × 2.\n",
    "5. A convolutional layer with 64 3 × 3 filters. \n",
    "6. A max Pooling Layer with size 2 × 2.\n",
    "7. A convolutional layer with 64 3 × 3 filters. \n",
    "7. A max Pooling Layer with size 2 × 2.\n",
    "9. A dense layer with 256 units.\n",
    "10. A dense layer with k units and softmax (aka cross entropy) loss function.\n",
    "\n",
    "Use the sigmoid activation function for all layers but the last one which uses the softmax. Use default values for the parameters which are not specified above.\n",
    "\n",
    "a) <font color=Red>[5pts]</font> Determine the right value for k and write the value for k you use at the end of the notebook. Write the code to solve a) in the cell below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1681117494803,
     "user": {
      "displayName": "Pegasus Lee",
      "userId": "06519879725136127673"
     },
     "user_tz": -480
    },
    "id": "NCTRHA6eZeNZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='sigmoid'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='sigmoid',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "\n",
    "# write your own code for a) here\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='sigmoid'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='sigmoid'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='sigmoid'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='sigmoid'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjYALfOJZeNZ"
   },
   "source": [
    "b) <font color=Red>[5pts]</font> The architecture defined above cannot be built because of an error. You should fix such an error **without changing the number of convolutional, pooling or dense layers, the number of filters, the size of the filters, or the number of units**. Write at the end of the notebook which strategy did you use and write the code to solve b) in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1681117500264,
     "user": {
      "displayName": "Pegasus Lee",
      "userId": "06519879725136127673"
     },
     "user_tz": -480
    },
    "id": "BgFZ5qvyZeNZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='sigmoid',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "\n",
    "\n",
    "# write your own code for b) here\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='sigmoid'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='sigmoid'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='sigmoid'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='sigmoid'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSbMS0gmZeNa"
   },
   "source": [
    "## Question 2 (Training a small CNN from scratch)\n",
    "\n",
    "We are now considering a different CNN architecture specified in the code below. **Fill the missing parts (there is a comment (#) specifying which parts must be filled)**. After that, you should train such a CNN using the following values for the parameters:\n",
    "\n",
    "- loss function = crossentropy;\n",
    "- optimizer RMSprop with learning rate = 0.1;\n",
    "- metrics = accuracy;\n",
    "- Batch size for the training/validation generators = 20; \n",
    "- epochs = 30.\n",
    "\n",
    "*Write your codes below and some answers at the end of the notebook again. Plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6ez4gkSZeNa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='sigmoid',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='sigmoid',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='sigmoid',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='sigmoid',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# something is missing here \n",
    "model.add(layers.Dense(512, activation='sigmoid'))\n",
    "model.add(layers.Dense(k, activation='softmax')) # replace k with the corresponding value\n",
    "\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "model.compile( # fill this part ...\n",
    "    \n",
    "   \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './cat_dog_car_bike'\n",
    "train_dir= os.path.join(base_dir, 'train')\n",
    "validation_dir= os.path.join(base_dir, 'val')\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(32, 32),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(32, 32),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator)\n",
    "\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSruCWRsZeNb"
   },
   "source": [
    "a) <font color=Red>[5pts]</font> What is the main problem for your model?\n",
    "\n",
    "1. Overfitting\n",
    "2. Underfitting\n",
    "\n",
    "Write your answer below at the end of the notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUUJYUdxZeNb"
   },
   "source": [
    "b) <font color=Red>[5pts]</font> **Without changing the learning rate**, change one hyperparameter so as to improve the training error. Which hyperparameters did you change? **This is just one question, In the below code, you can should change the learning rate as well.**\n",
    "\n",
    "*Write your codes **Note that you should also change the learning rate(larger or smaller) in the code** below and some answers at the end of the notebook again. Plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots below:*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3DeWcq2ZeNc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='sigmoid',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='sigmoid',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='sigmoid',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='sigmoid',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='sigmoid'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './cat_dog_car_bike'\n",
    "train_dir= os.path.join(base_dir, 'train')\n",
    "validation_dir= os.path.join(base_dir, 'val')\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(32, 32),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(32, 32),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pX2qBmPOZeNc"
   },
   "source": [
    "## Question 3 (Optimize the learning rate) \n",
    "\n",
    "a)<font color=Red>[10pts]</font> Determine an interval [a,b] of possible values for the learning rate, which is “wide enough”. In particular, you should try to guarantee that **your interval contains an optimal value for the learning rate**. At the same time the interval that you provided should not be too wide, due to efficiency reasons. In particular, your interval [a,b] should be such that $\\frac{b}{a} \\leq 10$. e.g. [1e-4, 1e-5].\n",
    "\n",
    "b)<font color=Red>[15pts]</font> Provide a \"good\" value for the learning rate. In particular, <font color=Red>**the training accuracy should become larger than 0.9**</font> or **the training loss should become smaller than 0.3** within 30 epochs. <font color=Red>**Note that you can change other hyperparameters like activation function as well for the code.**</font>\n",
    "\n",
    "*Write your codes below and some answers at the end of the notebook again. Plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots below:*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3lvnLrOZeNc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "train_dir = './data/train'\n",
    "validation_dir = './data/validation'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "# Build model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Set CLR parameters\n",
    "lr_triangular2 = lambda x: 1. / (2.**(x-1))\n",
    "max_lr = 1e-2\n",
    "min_lr = 1e-7\n",
    "epochs_per_cycle = 30\n",
    "num_cycles = 5\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)]\n",
    "\n",
    "# Fit model with CLR\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=epochs_per_cycle*num_cycles,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      callbacks=callbacks,\n",
    "      verbose=2,\n",
    "      # Set CLR parameters\n",
    "      learning_rate=lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxVBVD06ZeNd"
   },
   "source": [
    "\n",
    "## Question 4 (Transfer Learning) <font color=Red>[25pts]</font>\n",
    "\n",
    "Use the VGG16 as feature extractor with data augmentation (i.e. remove the top layer and freeze the VGGnet). You should try to achieve a **validation accuracy of at least 94\\%**. Report the accuracy of your model on the test set.\n",
    "\n",
    "*Write your codes below and some answers at the end of the notebook again. Plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUg7PW_UZeNd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Load the VGG16 network\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))\n",
    "\n",
    "# Freeze the layers\n",
    "conv_base.trainable = False\n",
    "\n",
    "# Define the data directories\n",
    "base_dir = '/content/drive/MyDrive/Colab Notebooks/hw3_dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Define the data augmentation parameters\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Validation and test data should not be augmented\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 20\n",
    "\n",
    "# Create the generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=50)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-nvbdppZeNd"
   },
   "source": [
    "## Question 5 (Open Question) <font color=Red>[25pts]</font>\n",
    "\n",
    "Use any of the techniques we saw during our course so as to improve the validation accuracy of your CNN. You should try to achieve a **validation accuracy of at least 96\\%** and in any case better than the validation accuracy provided in question 4. Report the accuracy of your model on the test set.Your model should have **max size of 300Mb**.\n",
    "\n",
    "<font color=Red>**Note that you can just modify the model in Q4 like freezing part of VGG16 model to improve the accuaracy further, even though we recommond you to change a backbone like ResNet.**</font>\n",
    "\n",
    "*Write your codes below and some answers at the end of the notebook again. Plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkBvEQjNZeNd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the ResNet50V2 model, but not the top layers\n",
    "conv_base = ResNet50V2(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "conv_base.trainable = False\n",
    "\n",
    "# Define the new model with the ResNet50V2 layers and new top layers\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                              target_size=(150, 150),\n",
    "                                                              batch_size=20,\n",
    "                                                              class_mode='binary')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=50,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=50)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_generator = validation_datagen.flow_from_directory(test_dir,\n",
    "                                                         target_size=(150, 150),\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode='binary')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('test accuracy:', test_acc)\n",
    "\n",
    "# Save the model\n",
    "model.save('modelQ5.h1') # important do not change the name of the model\n",
    "\n",
    "# Plot the accuracy and loss curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HL9tGJAnZeNd"
   },
   "source": [
    "## Answers\n",
    "\n",
    "Write your answers for these questions below in the box.\n",
    "\n",
    "Question 1\n",
    "* a) What is the right value of k?\n",
    "###### ans k = 10\n",
    "\n",
    "* b) How did you fix the error in the architecture?\n",
    " ###### Ans.The error in the architecture is related to the mismatch between the output shape of the last convolutional layer and the input shape of the first dense layer. The output shape of the last convolutional layer is (1, 1, 64), which means that the input to the dense layer has shape (1, 1, 64). However, the dense layer is expecting a 1D input of shape (256,).To fix this error, I flatten the output of the last convolutional layer before feeding it to the dense layers. I also added a Flatten layer after the last MaxPooling2D layer to reshape the output into a 1D array.\n",
    "\n",
    "Question 2\n",
    "* a) There was a problem of underfitting or overfitting?\n",
    "###### No. Neither overfitting nor undefitting was seen in this model. This is because both the training data for this model was sufficient\n",
    "* b) Which hyperparameter did you change?\n",
    "###### I decreased the learning rate to prevent the optimizer from overshooting the minimum of the loss function.\n",
    "\n",
    "Question 3\n",
    "* a) which interval for the learning rate did you consider?\n",
    "###### based on the learning rate range test proposed by Leslie Smith we can set the interval [a, b] as [1e-7, 1e-2].\n",
    "* b) which value for the learning rate did you consider?\n",
    "###### I considered the Cyclical Learning Rates (CLR) approach to find a good value for the learning rate\n",
    "\n",
    "Question 4\n",
    "* a) what is the validation accuracy of the modified VGG16 model?\n",
    "###### 90.5%\n",
    "* b) what is the test accuracy of the modified VGG16 model?\n",
    "###### 88.2%\n",
    "\n",
    "Question 5\n",
    "* a) what is the validation accuracy of your own model?\n",
    "###### 82.5%\n",
    "* b) what is the test accuracy of your own model?\n",
    "###### 85.1%\n",
    "* c) provide your model with a cloud link (eg: Google Drive, One Drive or Baiduyun Drive)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "17DF-ggGfmm1PwDMVu-CqTcA3vr5LJANc",
     "timestamp": 1681117594810
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
